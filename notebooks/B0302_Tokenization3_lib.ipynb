{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization ( or Segmentation )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interior boundary scoring에는 앞서 설명한 Cohesion Score 이외에 다양한 공식을 적용시킬 수 있다. 글자와 글자 사이에 관계를 정량화 할 수 있는 방법이 있다면 이를 적용시킬 수 있다. \n",
    "\n",
    "여기에서는 이상의 내용을 liabrary로 만들어 보고 예시 데이터 전체를 Segmentation 해 보자. 아울러 앞서 설명한 Cohesion Score 이외에 t-score와 simple-log-likelihood-ratio의 값을 추가로 적용시켜보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from time import time\n",
    "from collections import Counter\n",
    "from tqdm import tqdm_notebook\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram( text, n=2 ):\n",
    "    size = len( text )\n",
    "    grams = [ text[i:i+n] for i in range(size -n+1 ) ]\n",
    "    return grams\n",
    "\n",
    "def get_allgrams( line, counter=Counter(), n_min=2, n_max=8):\n",
    "    \"\"\"\n",
    "    n_min=2, n_max=8 : # 1-gram, 2-gram, 3-gram .... 8-gram\n",
    "    corpus = [doc1, doc2, ... docn]\n",
    "    \"\"\"\n",
    "    ns = range( n_min, n_max+1 ) \n",
    "    for n in ns:\n",
    "        counter.update(  n_gram( line, n ) )\n",
    "    return counter\n",
    "\n",
    "def expected_value( term, unigrams, allgrams, corpora_size ):\n",
    "    size = len( term )\n",
    "    chrs = list( term )\n",
    "    o = allgrams.get( term ) if allgrams.get( term ) else 0\n",
    "    observed_chrs = [ unigrams.get( c ) if unigrams.get( c )  else 0 for c in chrs ]\n",
    "    mul = reduce(lambda x, y: x*y, observed_chrs )\n",
    "    e = mul / math.pow( corpora_size, size - 1 )\n",
    "    return ( o, e )\n",
    "\n",
    "def t_score( o, e ):\n",
    "    return ( o - e ) / math.sqrt( o + 1 )\n",
    "\n",
    "def sim_ll( o, e ):\n",
    "    if e == o or o == 0 : return 0\n",
    "    rst = 2 * ( o * math.log( o / e ) - ( o - e ) )\n",
    "    if o >= e : return rst\n",
    "    else : return -1 * rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CohesionTokenizer():\n",
    "    \n",
    "    def __init__( self, alpha=0 ):\n",
    "        self.train_allgrams = Counter()\n",
    "        self.train_unigrams = Counter()\n",
    "        self.mark_in = \" _¶{:d}_ \"\n",
    "        self.mark_out = \"_¶{:d}_\"\n",
    "        self.alpha = alpha\n",
    "        self.corpora_size = 0\n",
    "    \n",
    "    def fit( self, corpus, min_tf=5 ):\n",
    "        \n",
    "        q_ = time()\n",
    "        \n",
    "        for line in tqdm_notebook( corpus ): \n",
    "            self.train_unigrams.update( list( line ) )\n",
    "            get_allgrams( line, self.train_allgrams )\n",
    "            self.corpora_size += len( line )\n",
    "\n",
    "        self.train_unigrams = Counter( { x : self.train_unigrams[x] for x in self.train_unigrams if self.train_unigrams[x] >= min_tf } )\n",
    "        self.train_allgrams = Counter( { x : self.train_allgrams[x] for x in self.train_allgrams if self.train_allgrams[x] >= min_tf } )\n",
    "        \n",
    "        def _cohesion( term ):\n",
    "            size = len( term )\n",
    "            numerator = self.train_allgrams.get( term )\n",
    "            denominator = self.train_unigrams.get( term[0] )\n",
    "            if not numerator : numerator = 0\n",
    "            if not denominator : denominator = 0.2\n",
    "            return math.pow( ( numerator/denominator), (1/ (size-self.alpha)  ) )\n",
    "        \n",
    "        def _t_score( term ):\n",
    "            o, e = expected_value( term, self.train_unigrams, self.train_allgrams, self.corpora_size )\n",
    "            return t_score( o, e )\n",
    "            \n",
    "        def _simple_ll( term ):\n",
    "            o, e = expected_value( term, self.train_unigrams, self.train_allgrams, self.corpora_size )\n",
    "            return sim_ll( o, e )\n",
    "        \n",
    "        self.interior_boundary_calcurator = {\n",
    "            \"cohesion\": _cohesion,\n",
    "            \"t_score\": _t_score,\n",
    "            \"simple_ll\": _simple_ll,\n",
    "        }\n",
    "        \n",
    "        print( \"* Fitting ... Done ({:.03f} sec)\".format( time() - q_ ) )\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform( self, test, method=\"cohesion\" ):\n",
    "        \n",
    "        self.test = test\n",
    "        self.test_allgrams = Counter()\n",
    "        self.test_cohesions = []\n",
    "        interior_boundary_calcurator = self.interior_boundary_calcurator.get( method ) if self.interior_boundary_calcurator.get( method ) else self.interior_boundary_calcurator.get( \"cohesion\" )\n",
    "        \n",
    "        ## Get All grams\n",
    "        q_ = time()\n",
    "        \n",
    "        for line in self.test:\n",
    "            get_allgrams( line, self.test_allgrams )\n",
    "    \n",
    "        print( \"* Allgram Extraction ... Done ({:.03f} sec)\".format( time() - q_ ) )\n",
    "        \n",
    "        ## Get Cohesion Score\n",
    "        q_ = time()\n",
    "        for t_, f_ in self.test_allgrams.items():\n",
    "            c_ = interior_boundary_calcurator( t_ )\n",
    "            if c_ <= 0 : continue\n",
    "            self.test_cohesions.append( ( t_, f_, c_ ) )\n",
    "        \n",
    "        self.test_cohesions = sorted( self.test_cohesions, key=lambda x: -x[2] )\n",
    "\n",
    "        print( \"* Cohesion Score Calcuration ... Done ({:.03f} sec)\".format( time() - q_ ) )\n",
    "        \n",
    "        # Segment\n",
    "        q_ = time()\n",
    "        self.test_segmented = []\n",
    "        cohesions_iter = list( enumerate( self.test_cohesions ) )\n",
    "        \n",
    "        for line in tqdm_notebook( self.test ):\n",
    "            data_ = line + \"\"\n",
    "            token_box_ = []\n",
    "            \n",
    "            for i, t_ in cohesions_iter:\n",
    "                if t_[0] not in data_ : continue\n",
    "                data_ = data_.replace( t_[0], self.mark_in.format(i) )\n",
    "                token_box_.append( ( self.mark_out.format(i), t_[0] ) )\n",
    "\n",
    "            for m, t in token_box_:\n",
    "                data_ = data_.replace( m, t )\n",
    "\n",
    "            self.test_segmented.append( data_.strip() )\n",
    "\n",
    "        print( \"* Segmentation ... Done ({:.03f} sec)\".format( time() - q_ ) )\n",
    "        \n",
    "        return self.test_segmented\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6e47a83cfa4823af12ed68af484cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=34070), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Fitting ... Done (3.889 sec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16baf5d74b504d629ed79a4437321d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16555), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Fitting ... Done (3.837 sec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955204ef202b409184c529b545b2cc8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16555), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Fitting ... Done (3.807 sec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.CohesionTokenizer at 0x1ba0b401978>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_path = [\"../data/DYBG_tn.txt\", \"../data/GAZS_tn.txt\", \"../data/YHYM_tn.txt\"]\n",
    "corpus1 = open( corpus_path[0], 'r', encoding=\"utf-8\").readlines()\n",
    "corpus2 = open( corpus_path[1], 'r', encoding=\"utf-8\").readlines()\n",
    "corpus3 = open( corpus_path[1], 'r', encoding=\"utf-8\").readlines()\n",
    "\n",
    "ct = CohesionTokenizer( alpha=0 )\n",
    "ct.fit( corpus1 )\n",
    "ct.fit( corpus2 )\n",
    "ct.fit( corpus3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Allgram Extraction ... Done (0.000 sec)\n",
      "* Cohesion Score Calcuration ... Done (0.002 sec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f3c4d828ee402e9325f9a6b2b4d7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Segmentation ... Done (0.017 sec)\n",
      "* Allgram Extraction ... Done (0.001 sec)\n",
      "* Cohesion Score Calcuration ... Done (0.005 sec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d14a5698a544dfabc597289f7864f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Segmentation ... Done (0.016 sec)\n",
      "* Allgram Extraction ... Done (0.000 sec)\n",
      "* Cohesion Score Calcuration ... Done (0.003 sec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5fb101d974458597343838cc83fd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Segmentation ... Done (0.016 sec)\n",
      "治 勞役  太甚 或 飮食  失節  身熱  而煩  自汗  倦怠  黃芪   一錢 半 人參  白朮  甘草  各一 錢 當歸 身 陳皮  各五分  升麻  柴胡  各三  分右  剉作一貼 水 煎服\n",
      "治 勞役  太甚 或 飮食  失節  身熱  而煩  自汗  倦怠  黃芪   一錢 半 人參  白朮  甘草 各 一錢  當歸 身 陳皮 各 五分  升麻  柴胡  各三 分 右剉  作一貼 水 煎服\n",
      "治 勞役  太甚 或 飮食  失節  身熱  而煩  自汗  倦怠  黃芪   一錢 半 人參  白朮  甘草  各一錢  當歸 身 陳皮  各五分  升麻  柴胡  各三 分 右剉作一貼  水煎服\n",
      "\n",
      "止代 脈見  宜服 灸 甘草 湯 人參 黃 芪湯  脈虛 軟 宜服  茯神  湯補  氣湯\n",
      "止代 脈見  宜服 灸 甘草 湯 人參  黃芪 湯 脈虛 軟 宜服  茯神  湯補  氣湯\n",
      "止代 脈見  宜服 灸 甘草 湯 人參  黃芪 湯 脈虛 軟 宜服  茯神  湯補  氣湯\n",
      "\n",
      "煩 主氣 躁 主血  肺主皮毛 氣 熱則 煩 腎主  津液  血熱 則躁 故用  梔子  以治 肺 豆豉  以潤 腎宜 黃連  鷄子 湯 甘草  乾薑 湯 芍藥  甘草 湯 入門\n",
      "煩 主氣 躁 主血  肺主  皮毛 氣 熱則 煩 腎主  津液 血 熱則 躁 故用  梔子 以 治肺  豆豉  以潤 腎宜 黃連 鷄 子湯  甘草  乾薑 湯 芍藥  甘草 湯 入門\n",
      "煩 主氣 躁 主血  肺主  皮毛 氣 熱則 煩 腎主  津液 血 熱則 躁 故用  梔子 以 治肺  豆豉  以潤 腎宜 黃連 鷄 子湯  甘草  乾薑 湯 芍藥  甘草 湯 入門\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1 = \"治勞役太甚或飮食失節身熱而煩自汗倦怠黃芪 一錢半人參白朮甘草各一錢當歸身陳皮各五分升麻柴胡各三分右剉作一貼水煎服\"\n",
    "data2 = \"止代脈見宜服灸甘草湯人參黃芪湯脈虛軟宜服茯神湯補氣湯\"\n",
    "data3 = \"煩主氣躁主血肺主皮毛氣熱則煩腎主津液血熱則躁故用梔子以治肺豆豉以潤腎宜黃連鷄子湯甘草乾薑湯芍藥甘草湯入門\"\n",
    "seg1 = ct.transform( [data1, data2, data3], method=[\"cohesion\", \"t_score\", \"simple_ll\"][0] )\n",
    "seg2 = ct.transform( [data1, data2, data3], method=[\"cohesion\", \"t_score\", \"simple_ll\"][1] )\n",
    "seg3 = ct.transform( [data1, data2, data3], method=[\"cohesion\", \"t_score\", \"simple_ll\"][2] )\n",
    "rst = list( zip( seg1, seg2, seg3 ) )\n",
    "for l in rst:\n",
    "    print( \"\\n\".join(l) )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('甘草', 4, 34365.97750930184),\n",
       " ('甘草湯', 2, 1945.9564822225157),\n",
       " ('灸甘草', 1, 504.48312157806305),\n",
       " ('灸甘草湯', 1, 115.34145653853527),\n",
       " ('灸甘', 1, 76.87907078418132)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = [\"炙甘草湯\", \"灸甘草湯\", \"甘草\", \"甘草湯\", \"灸甘草\", \"灸甘\"]\n",
    "\n",
    "[ s for s in  ct.test_cohesions if s[0] in sample ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Allgram Extraction ... Done (2.432 sec)\n",
      "* Cohesion Score Calcuration ... Done (2.857 sec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a27a56fcf284ab288491c2942e77836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=34070), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Segmentation ... Done (732.126 sec)\n",
      "# Corpus Segmentation Done! \n"
     ]
    }
   ],
   "source": [
    "seg = ct.transform( corpus1, method=\"cohesion\" )\n",
    "\n",
    "corpus_seg_path = \"../data/DYBG_seg.txt\"\n",
    "with open( corpus_seg_path, 'w', encoding=\"utf-8\") as fl:\n",
    "    fl.write( \"\\n\".join( seg ) )\n",
    "\n",
    "print(\"# Corpus Segmentation Done! \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REF\n",
    "\n",
    "* [Cohesion score + L-Tokenizer. 띄어쓰기가 잘 되어있는 한국어 문서를 위한 unsupervised tokenizer](https://lovit.github.io/nlp/2018/04/09/cohesion_ltokenizer/)\n",
    "* [ratsgo's blog > Cohesion Probability](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/05/05/cohesion/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
