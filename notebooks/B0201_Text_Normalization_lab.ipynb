{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization\n",
    "\n",
    "자주 마주치는 문제와 현실적인 해결 방법에 대해 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Hanzi\n",
    "\n",
    "주어진 텍스트에서 한자와 한자 아닌 것을 분리해야할 때가 있다. 한자의 유니코드 범위가 다양하기 때문에 이를 고려하여 추출한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Duplicates & Variants\n",
    "\n",
    "주어진 텍스트에서 다중코드자 및 이체자를  병합하면 분석 과정의 오류를 줄일 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한자 추출해 내기\n",
    "\n",
    "import re\n",
    "\n",
    "def get_cjk_unicode_range():\n",
    "    cjk_unicode_range = {\n",
    "        \"Unified_Ideographs\" : \"\\u4E00-\\u9FCF\",\n",
    "        \"Unified_Ideographs_ExA\" : \"\\u3400-\\u4DBF\",\n",
    "        \"Unified_Ideographs_ExB\" : \"\\u20000-\\u2A6DF\",\n",
    "        \"Unified_Ideographs_ExC\" : \"\\u2A700-\\u2B73F\",\n",
    "        \"Unified_Ideographs_ExD\" : \"\\u2B740-\\u2B81F\",\n",
    "        \"Compatibility_Ideographs\" : \"\\uF900-\\uFAFF\",\n",
    "        \"Compatibility_Ideographs_Supplement\": \"\\u2F800-\\u2FA1F\",\n",
    "        \"Radicals\": \"\\u2F00-\\u2FDF\",\n",
    "        \"Radicals_Supplement\": \"\\u2E80-\\u2EFF\",\n",
    "        \"Strokes\": \"\\u31C0-\\u31EF\",\n",
    "        \"Ideographic_Description_Characters\": \"\\u2FF0-\\u2FFF\"\n",
    "    }\n",
    "\n",
    "    cjk_range = \"[\" + \"\".join( list( cjk_unicode_range.values() ) ) + \"]\"\n",
    "    none_cjk_range = \"[^\" + \"\".join( list( cjk_unicode_range.values() ) ) + \"]\"\n",
    "    cjk_range_re = re.compile( cjk_range )\n",
    "    none_cjk_range_re = re.compile( none_cjk_range )\n",
    "#     cjk_range_re = re.compile( cjk_range , re.DEBUG)\n",
    "#     none_cjk_range_re = re.compile( none_cjk_range , re.DEBUG)\n",
    "    \n",
    "    return ( cjk_range_re, none_cjk_range_re )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dicts( dict_path ):\n",
    "    with open( dict_path, 'r', encoding=\"utf-8\") as fl:\n",
    "        _dc = fl.readlines()\n",
    "    dc = [ [ c.strip() for c in _d.split(\"\\t\") ] for _d in _dc ]\n",
    "    return dc\n",
    "\n",
    "def get_duplicates_dict():\n",
    "    return get_dicts( \"../data/hanzi_duplicates\" )\n",
    "\n",
    "def get_variants_dict():\n",
    "    return get_dicts( \"../data/hanzi_variants\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HanziText:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cjk_range_re, self.none_cjk_ragne_re = get_cjk_unicode_range()\n",
    "        self.duplicates_dict = get_duplicates_dict()\n",
    "        self.variants_dict = get_variants_dict()\n",
    "        \n",
    "    def extract_hanzi(  self, text ):\n",
    "        return re.findall( self.cjk_range_re, text  )\n",
    "        \n",
    "    def exclude_hanzi(  self, text ):\n",
    "        return re.findall( self.none_cjk_ragne_re, text  )\n",
    "    \n",
    "    def _merge_chr_pair(  self, dictionary, text ):\n",
    "        _text = text + \"\"\n",
    "        for a, b in dictionary:\n",
    "            _text = _text.replace( a, b )\n",
    "        return _text\n",
    "    \n",
    "    def merge_duplicates( self, text ):\n",
    "        return self._merge_chr_pair( self.duplicates_dict,  text )\n",
    "        \n",
    "    def merge_variants(  self, text ):\n",
    "        return self._merge_chr_pair( self.variants_dict,  text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = HanziText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 한자인 것:  葛根四两麻黄三两去节桂二两去皮芍药二两切甘草二两炙生姜三两切大枣十二枚掰右七味口父咀以水一斗先煮麻黄葛根减二升去沫内诸药煮取三升去滓温服一升复取微似汗不须啜粥余如桂枝法将息及禁忌太阳与阳明合病者必自下利葛根汤主之太阳与阳明合病不下利但呕者葛根加半夏汤主之\n",
      "* 한자 아닌 것: 　（）　（）（）　（）　（）（）（），，，，，，，，，，，。，，。，，，。\n"
     ]
    }
   ],
   "source": [
    "text = \"葛根四两　麻黄三两（去节）　桂二两（去皮）芍药二两（切）　甘草二两（炙）　生姜三两（切）大枣十二枚（掰）右七味（口父）咀，以水一斗，先煮麻黄葛根，减二升，去沫，内诸药，煮取三升，去滓，温服一升，复取微似汗，不须啜粥，余如桂枝法将息及禁忌。太阳与阳明合病者，必自下利，葛根汤主之。太阳与阳明合病，不下利，但呕者，葛根加半夏汤主之。\"\n",
    "\n",
    "print( \"* 한자인 것: \", \"\".join( tn.extract_hanzi( text ) ) )\n",
    "print( \"* 한자 아닌 것:\", \"\".join( tn.exclude_hanzi( text ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "葛根四两麻黄三两去节桂二两去皮芍药二两切甘草二两炙生姜三两切大枣十二枚掰右七味口父咀以水一斗先煮麻黄葛根减二升去沫内诸药煮取三升去滓温服一升复取微似汗不须啜粥余如桂枝法将息及禁忌太阳与阳明合病者必自下利葛根汤主之太阳与阳明合病不下利但呕者葛根加半夏汤主之\n"
     ]
    }
   ],
   "source": [
    "hanzi_only = \"\".join( tn.extract_hanzi( text ) )\n",
    "hanzi_dup_merged = tn.merge_duplicates( hanzi_only )\n",
    "print(hanzi_dup_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "葛根四兩麻黃三兩去節桂二兩去皮芍藥二兩切甘草二兩炙生姜三兩切大棗十二枚掰右七味口父咀以水一斗先煮麻黃葛根減二升去沫內諸藥煮取三升去滓溫服一升復取微似汗不須啜粥余如桂枝法將息及禁忌太陽與陽明合病者必自下利葛根湯主之太陽與陽明合病不下利但嘔者葛根加半夏湯主之\n"
     ]
    }
   ],
   "source": [
    "hanzi_var_merged = tn.merge_variants( hanzi_dup_merged )\n",
    "print( hanzi_var_merged )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※ variants dictionary file를 이중코드자로 합쳐 놓치 않으면 병합되지 않는 글자가 발생할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( \"../data/hanzi_variants\", 'r', encoding=\"utf-8\" ) as fl:\n",
    "    new_dict = tn.merge_duplicates( fl.read() )\n",
    "    \n",
    "with open( \"../data/hanzi_variants\", 'w', encoding=\"utf-8\" ) as fl:\n",
    "    fl.write( new_dict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
