{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity and Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "피처 사이의 관계는 벡터 사이의 관계로 환원될 수 있다. 벡터 사이의 관계는 다시 서로 얼마나 비슷한가, 반대로 얼마나 떨어져 있는가라는 물음으로 환원될 수 있다. \n",
    "\n",
    "따라서 벡터 사이의 유사도()와 거리()를 구해야 할 필요가 생겨난다. \n",
    "\n",
    "유사도와 거리는 반대 대체로 반대 개념이지만, 각각의 특징이 있다. \n",
    "\n",
    "* 유사도\n",
    "  - \"얼마나 비슷한가\"에 대한 값이다.\n",
    "  - 주로 0에서 1 사이의 값을 가지며, 0은 전혀 같지 않은 상태(벡터에서의 직교와 같은 위상), 1은 완전히 같은 상태.\n",
    "  \n",
    "* 거리\n",
    "  - \"얼마나 떨어져 있는가\"에 대한 값이다.\n",
    "  - 주로 0에서 무한대의 값을 가진다. 0은 완전히 같은 상태.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유사도를 구하는 방법은 매우 다양하다. 그 가운데 가장 보편적으로 사용하는 방법은 코사이 유사도(cosine similarity)이다. \n",
    "\n",
    "코사인 유사도는 두 벡터가 이루는 내각의 코사인 값을 의미한다. 따라서 직교하면 0이 되고, 완전히 일치하면 1이 된다. \n",
    "\n",
    "코사인 유사도는 두 벡터의 내적을 이용하여 간단하게 구할 수 있기 때문에 계산에 있어서도 유리하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "거리를 구하는 방법 역시 다양하다. 그 가운데 가장 보편적으로 사용하는 방법은 유클리디안 거리(Euclidian distance)이다. \n",
    "\n",
    "유클리디안 거리는 두 벡터 사이의 직선 거리를 의미한다. 따라서 완전히 같은 곳에 있으면 0이 되고, 거리가 늘어남에 따라 크기가 커진다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = \"../data/formulas.txt\"\n",
    "corpus_ = open( corpus_path, 'r', encoding='utf-8' ).read()\n",
    "header, corpus_raw = corpus_.split(\"***\")\n",
    "corpus_raw = corpus_raw.strip()\n",
    "corpus = [ line.strip() for line in corpus_raw.split(\"\\n\") ]\n",
    "corpus_tokenized = [ line.split() for line in corpus ]\n",
    "\n",
    "print( \"# Corpus Description\" )\n",
    "print( header.strip() )\n",
    "print()\n",
    "print( \"# Corpus Size: \", len(corpus) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build TF Matrix and TF-IDF Matrix\n",
    "\n",
    "t0 = time()\n",
    "tf_vectorizer = CountVectorizer( min_df=min_df )\n",
    "tf = tf_vectorizer.fit_transform( corpus )\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print( \"TF Matrix done in {:03f}s.\".format(time() - t0) )\n",
    "\n",
    "t0 = time()\n",
    "tfidf_vectorizer = TfidfVectorizer( min_df=min_df )\n",
    "tfidf = tfidf_vectorizer.fit_transform( corpus )\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print( \"TF-IDF Matrix done in {:03f}s.\".format(time() - t0) )\n",
    "\n",
    "doc_size, feature_size = tf.shape\n",
    "print( \"# 처방 개수: \", doc_size)\n",
    "print( \"# 본초 개수: \", feature_size, \" ({}회 이상 사용된 본초)\".format( min_df ) ) \n",
    "\n",
    "term_vector_via_tf = tf.T\n",
    "term_vector_via_tfidf = tfidf.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_word = ( tf.T * tf )\n",
    "term_vector_via_coword = co_word\n",
    "print( \"{}개 본초에 대해 {} 길이의 벡터 생성\".format( *co_word.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed Value\n",
    "observed_v = co_word.toarray()\n",
    "\n",
    "# Expected Value\n",
    "margin_x = np.full( co_word.shape, freq_per_term )\n",
    "margin_y = margin_x.T\n",
    "expected_v = np.divide(  np.multiply( margin_x, margin_y ),  sum( freq_per_term )   )\n",
    "\n",
    "# T-score with addone smoothing\n",
    "observed_v_add1 = np.add( observed_v, 1 )\n",
    "t_score = np.divide( np.subtract( observed_v, expected_v ) , np.sqrt( observed_v_add1 ) )\n",
    "\n",
    "from scipy import sparse\n",
    "term_vector_via_tscore = sparse.csc_matrix( t_score )\n",
    "print( \"{}개 본초에 대해 {} 길이의 벡터 생성\".format( *term_vector_via_tscore.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "vec_size = 64\n",
    "pochs = 32\n",
    "max_formula_length = max( size_per_doc ) \n",
    "print( \"Window size: \", max_formula_length )\n",
    "\n",
    "w2v = gensim.models.Word2Vec( size=vec_size, window=max_formula_length, min_count=min_df, workers=10 )\n",
    "w2v_feature_names = w2v.build_vocab( corpus_tokenized )\n",
    "w2v.train( corpus_tokenized, total_examples=len( corpus_tokenized ), epochs=pochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_most_similar( test_herb, n=4 ):\n",
    "    return w2v.wv.most_similar( [ test_herb ], topn=n )\n",
    "\n",
    "w2v_most_similar( \"감초\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 결과 비교\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class MostElem:\n",
    "    \n",
    "    def __init__(self, feature_list, embedding_matrix, max_n=4):\n",
    "        self.feature_list = feature_list\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.max_n = max_n\n",
    "    \n",
    "    def most_similar( self, term ):\n",
    "        i = self.feature_list.index( term )\n",
    "        sims = cosine_similarity( self.embedding_matrix[i,:], self.embedding_matrix )\n",
    "        most_sim_idx = sims.argsort()[0][-self.max_n-1:-1].tolist()\n",
    "        most_sim_idx.reverse()\n",
    "        return [ ( self.feature_list[i], sims[0][i] ) for i in most_sim_idx ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_tf = MostElem( tf_feature_names, term_vector_via_tf, max_n=4  )\n",
    "by_tfidf = MostElem( tfidf_feature_names, term_vector_via_tfidf, max_n=4  )\n",
    "by_coword = MostElem( tf_feature_names, term_vector_via_coword, max_n=4  )\n",
    "by_tscore = MostElem( tf_feature_names, term_vector_via_tscore, max_n=4  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_herb = \"마황\"\n",
    "\n",
    "print( by_tf.most_similar( test_herb ) )\n",
    "print( by_tfidf.most_similar( test_herb ) )\n",
    "print( by_coword.most_similar( test_herb ) )\n",
    "print( by_tscore.most_similar( test_herb ) )\n",
    "print( w2v_most_similar( test_herb ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fm_chain( init_herb, most_fn ):\n",
    "    output = [init_herb]\n",
    "    next_herb = init_herb\n",
    "    i = 0\n",
    "    while i < 20:\n",
    "        next_herb = most_fn( next_herb )[0][0]\n",
    "        if next_herb in output:\n",
    "            break\n",
    "        output.append( next_herb )\n",
    "        i = i + 1\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(  fm_chain( \"인삼\", glove.most_similar ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
