{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity and Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "피처 사이의 관계는 벡터 사이의 관계로 환원될 수 있다. 벡터 사이의 관계는 다시 서로 얼마나 비슷한가, 반대로 얼마나 떨어져 있는가라는 물음으로 환원될 수 있다. \n",
    "\n",
    "따라서 벡터 사이의 유사도()와 거리()를 구해야 할 필요가 생겨난다. \n",
    "\n",
    "유사도와 거리는 반대 대체로 반대 개념이지만, 각각의 특징이 있다. \n",
    "\n",
    "* 유사도\n",
    "  - \"얼마나 비슷한가\"에 대한 값이다.\n",
    "  - 주로 0에서 1 사이의 값을 가지며, 0은 전혀 같지 않은 상태(벡터에서의 직교와 같은 위상), 1은 완전히 같은 상태.\n",
    "  \n",
    "* 거리\n",
    "  - \"얼마나 떨어져 있는가\"에 대한 값이다.\n",
    "  - 주로 0에서 무한대의 값을 가진다. 0은 완전히 같은 상태.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유사도를 구하는 방법은 매우 다양하다. 그 가운데 가장 보편적으로 사용하는 방법은 코사이 유사도(cosine similarity)이다. \n",
    "\n",
    "코사인 유사도는 두 벡터가 이루는 내각의 코사인 값을 의미한다. 따라서 직교하면 0이 되고, 완전히 일치하면 1이 된다. \n",
    "\n",
    "코사인 유사도는 두 벡터의 내적을 이용하여 간단하게 구할 수 있기 때문에 계산에 있어서도 유리하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "거리를 구하는 방법 역시 다양하다. 그 가운데 가장 보편적으로 사용하는 방법은 유클리디안 거리(Euclidian distance)이다. \n",
    "\n",
    "유클리디안 거리는 두 벡터 사이의 직선 거리를 의미한다. 따라서 완전히 같은 곳에 있으면 0이 되고, 거리가 늘어남에 따라 크기가 커진다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서는 word vector를 구한 뒤에, word vector 사이의 코사인 유사도를 통해 가장 비슷한 단어들을 연쇄적으로 추출하는 작업을 수행해 보고자 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Corpus Description\n",
      "- 출처 : 한국전통지식포탈(www.koreantk.com) > 전통의료 > 처방\n",
      "- 특징 : 본초 구성만 추출한 데이터\n",
      "- 데이터 생성일 : 2016.01.16\n",
      "\n",
      "# Corpus Size:  19162\n"
     ]
    }
   ],
   "source": [
    "corpus_path = \"../data/formulas.txt\"\n",
    "corpus_ = open( corpus_path, 'r', encoding='utf-8' ).read()\n",
    "header, corpus_raw = corpus_.split(\"***\")\n",
    "corpus_raw = corpus_raw.strip()\n",
    "corpus = [ line.strip() for line in corpus_raw.split(\"\\n\") ]\n",
    "corpus_tokenized = [ line.split() for line in corpus ]\n",
    "\n",
    "print( \"# Corpus Description\" )\n",
    "print( header.strip() )\n",
    "print()\n",
    "print( \"# Corpus Size: \", len(corpus) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count based embedding : 1st Order Vector ( TF, TFIDF Vector )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Matrix done in 0.125026s.\n",
      "TF-IDF Matrix done in 0.128977s.\n",
      "# 처방 개수:  19162\n",
      "# 본초 개수:  916  (6회 이상 사용된 본초)\n"
     ]
    }
   ],
   "source": [
    "# Build TF Matrix and TF-IDF Matrix\n",
    "\n",
    "t0 = time()\n",
    "tf_vectorizer = CountVectorizer( min_df=min_df )\n",
    "tf = tf_vectorizer.fit_transform( corpus )\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print( \"TF Matrix done in {:03f}s.\".format(time() - t0) )\n",
    "\n",
    "t0 = time()\n",
    "tfidf_vectorizer = TfidfVectorizer( min_df=min_df )\n",
    "tfidf = tfidf_vectorizer.fit_transform( corpus )\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print( \"TF-IDF Matrix done in {:03f}s.\".format(time() - t0) )\n",
    "\n",
    "doc_size, feature_size = tf.shape\n",
    "print( \"# 처방 개수: \", doc_size)\n",
    "print( \"# 본초 개수: \", feature_size, \" ({}회 이상 사용된 본초)\".format( min_df ) ) \n",
    "\n",
    "term_vector_via_tf = tf.T\n",
    "term_vector_via_tfidf = tfidf.T\n",
    "\n",
    "freq_per_term = np.sum( tf, axis=0 ).flatten().tolist()[0]\n",
    "size_per_doc = np.sum( tf, axis=1 ).flatten().tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count based embedding : 2nd Order Vector ( Co-word, t-score Vector )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916개 본초에 대해 916 길이의 벡터 생성\n"
     ]
    }
   ],
   "source": [
    "co_word = ( tf.T * tf )\n",
    "term_vector_via_coword = co_word\n",
    "print( \"{}개 본초에 대해 {} 길이의 벡터 생성\".format( *co_word.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916개 본초에 대해 916 길이의 벡터 생성\n"
     ]
    }
   ],
   "source": [
    "# Observed Value\n",
    "observed_v = co_word.toarray()\n",
    "\n",
    "# Expected Value\n",
    "margin_x = np.full( co_word.shape, freq_per_term )\n",
    "margin_y = margin_x.T\n",
    "expected_v = np.divide(  np.multiply( margin_x, margin_y ),  sum( freq_per_term )   )\n",
    "\n",
    "# T-score with addone smoothing\n",
    "observed_v_add1 = np.add( observed_v, 1 )\n",
    "t_score = np.divide( np.subtract( observed_v, expected_v ) , np.sqrt( observed_v_add1 ) )\n",
    "\n",
    "from scipy import sparse\n",
    "term_vector_via_tscore = sparse.csc_matrix( t_score )\n",
    "print( \"{}개 본초에 대해 {} 길이의 벡터 생성\".format( *term_vector_via_tscore.shape ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction based embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Junho\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size:  55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2816139, 4486336)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "vec_size = 64\n",
    "pochs = 32\n",
    "max_formula_length = max( size_per_doc ) \n",
    "print( \"Window size: \", max_formula_length )\n",
    "\n",
    "w2v = gensim.models.Word2Vec( size=vec_size, window=max_formula_length, min_count=min_df, workers=10 )\n",
    "w2v_feature_names = w2v.build_vocab( corpus_tokenized )\n",
    "w2v.train( corpus_tokenized, total_examples=len( corpus_tokenized ), epochs=pochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('자감초', 0.7659971117973328),\n",
       " ('분초', 0.5264178514480591),\n",
       " ('건갈', 0.39061635732650757),\n",
       " ('천궁', 0.39024609327316284)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def w2v_most_similar( test_herb, n=4 ):\n",
    "    return w2v.wv.most_similar( [ test_herb ], topn=n )\n",
    "\n",
    "w2v_most_similar( \"감초\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 비교\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class MostElem:\n",
    "    \n",
    "    def __init__(self, feature_list, embedding_matrix, max_n=4):\n",
    "        self.feature_list = feature_list\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.max_n = max_n\n",
    "    \n",
    "    def most_similar( self, term ):\n",
    "        i = self.feature_list.index( term )\n",
    "        sims = cosine_similarity( self.embedding_matrix[i,:], self.embedding_matrix )\n",
    "        most_sim_idx = sims.argsort()[0][-self.max_n-1:-1].tolist()\n",
    "        most_sim_idx.reverse()\n",
    "        return [ ( self.feature_list[i], sims[0][i] ) for i in most_sim_idx ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_tf = MostElem( tf_feature_names, term_vector_via_tf, max_n=4  )\n",
    "by_tfidf = MostElem( tfidf_feature_names, term_vector_via_tfidf, max_n=4  )\n",
    "by_coword = MostElem( tf_feature_names, term_vector_via_coword, max_n=4  )\n",
    "by_tscore = MostElem( tf_feature_names, term_vector_via_tscore, max_n=4  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('행인', 0.2784141049539053), ('감초', 0.24777930727725683), ('백지', 0.19616577223915038), ('길경', 0.18640087762763416)]\n",
      "[('행인', 0.31925387801792854), ('감초', 0.22711443809166312), ('계지', 0.17022316683287525), ('석고', 0.1555594113372934)]\n",
      "[('감초', 0.7447285115699573), ('길경', 0.7130944511806897), ('백지', 0.7097225397218855), ('행인', 0.6967252582467951)]\n",
      "[('백지', 0.8559774858181822), ('방풍', 0.8558905512591956), ('길경', 0.8555074442828369), ('감초', 0.8524383084076438)]\n",
      "[('세신', 0.4089393615722656), ('방풍', 0.401573121547699), ('전호', 0.3826691508293152), ('강활', 0.3817547559738159)]\n"
     ]
    }
   ],
   "source": [
    "test_herb = \"마황\"\n",
    "\n",
    "print( by_tf.most_similar( test_herb ) )\n",
    "print( by_tfidf.most_similar( test_herb ) )\n",
    "print( by_coword.most_similar( test_herb ) )\n",
    "print( by_tscore.most_similar( test_herb ) )\n",
    "print( w2v_most_similar( test_herb ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formula Generating Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fm_chain( init_herb, most_fn ):\n",
    "    output = [init_herb]\n",
    "    next_herb = init_herb\n",
    "    i = 0\n",
    "    while i < 20:\n",
    "        next_herb = most_fn( next_herb )[0][0]\n",
    "        if next_herb in output:\n",
    "            break\n",
    "        output.append( next_herb )\n",
    "        i = i + 1\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['부자', '건강']\n",
      "['부자', '건강']\n",
      "['부자', '건강', '백출', '인삼']\n",
      "['부자', '육계', '당귀', '천궁']\n",
      "['부자', '포부자', '교이', '이당']\n"
     ]
    }
   ],
   "source": [
    "test_herb = \"부자\"\n",
    "\n",
    "print(  fm_chain( test_herb, by_tf.most_similar ) )\n",
    "print(  fm_chain( test_herb, by_tfidf.most_similar ) )\n",
    "print(  fm_chain( test_herb, by_coword.most_similar ) )\n",
    "print(  fm_chain( test_herb, by_tscore.most_similar ) )\n",
    "print(  fm_chain( test_herb, w2v_most_similar ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
